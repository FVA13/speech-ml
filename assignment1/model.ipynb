{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:15:38.859121Z",
     "start_time": "2025-03-23T17:15:35.890536Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "from typing import (\n",
    "    Optional,\n",
    "    Any,\n",
    ")\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    classification_report,\n",
    ")\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from lightning.pytorch.callbacks import (\n",
    "    Callback,\n",
    "    ModelCheckpoint,\n",
    "    LearningRateMonitor,\n",
    "    EarlyStopping,\n",
    ")\n",
    "from lightning.pytorch.utilities.types import OptimizerLRScheduler\n",
    "\n",
    "import torchaudio\n",
    "from torchaudio import functional as F\n",
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4cf9a9533ba0a97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:15:38.869876Z",
     "start_time": "2025-03-23T17:15:38.868133Z"
    }
   },
   "outputs": [],
   "source": [
    "HW_PATH = Path(\"assignment1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dbe392368fd12",
   "metadata": {},
   "source": [
    "# 1. Check Mel Spectrogram implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "674192df337396e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:15:38.876449Z",
     "start_time": "2025-03-23T17:15:38.873833Z"
    }
   },
   "outputs": [],
   "source": [
    "from assignment1.melbanks import LogMelFilterBanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b01bb2ddc9439f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:15:39.568574Z",
     "start_time": "2025-03-23T17:15:39.079126Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://download.pytorch.org/torchaudio/tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n",
    "response = requests.get(url)\n",
    "audio_data = io.BytesIO(response.content)\n",
    "signal, sr = torchaudio.load(audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f16899080ab6a6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:15:39.607311Z",
     "start_time": "2025-03-23T17:15:39.586748Z"
    }
   },
   "outputs": [],
   "source": [
    "melspec = torchaudio.transforms.MelSpectrogram(\n",
    "    hop_length=160,\n",
    "    n_mels=80\n",
    ")(signal)\n",
    "logmelbanks = LogMelFilterBanks()(signal)\n",
    "\n",
    "assert torch.log(melspec + 1e-6).shape == logmelbanks.shape\n",
    "assert torch.allclose(torch.log(melspec + 1e-6), logmelbanks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc0e712de448829",
   "metadata": {},
   "source": [
    "# 2. Train CNN classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfa07f1d94b1cd8",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c40310e1231fed6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:15:39.627218Z",
     "start_time": "2025-03-23T17:15:39.623846Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    n_mels: int = 60  # {20, 40, 80}\n",
    "    groups: int = 1  # {1, 2, 4, 8, 16}\n",
    "    sample_rate: int = 16000\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    lr: float = 1e-4\n",
    "    warmup_epochs: int = 5\n",
    "    max_epochs: int = 2\n",
    "    batch_size: int = 32\n",
    "    gradient_clip_val: float = 1.0\n",
    "    scheduler_patience: int = 5\n",
    "    scheduler_factor: float = 0.5\n",
    "    checkpoint_dir: str = \"checkpoints\"\n",
    "    num_devices: int = 1\n",
    "    patience: int = 4\n",
    "    patience_min_delta: float = 1e-4\n",
    "    device: str = 'cpu'\n",
    "\n",
    "    # mlflow\n",
    "    mlflow_tracking_uri: str = \"http://127.0.0.1:5000\"\n",
    "    mlflow_experiment_name: str = \"Audio Binary Classification CNN\"\n",
    "    experiment_name: str = \"Audio Binary Classification CNN\"\n",
    "    run_name: str = \"baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ef5bc67783e02dc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:15:39.643832Z",
     "start_time": "2025-03-23T17:15:39.642062Z"
    }
   },
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    n_mels=80,  # {20, 40, 80}\n",
    "    groups=16,  # {1, 2, 4, 8, 16}\n",
    "    sample_rate=16000,\n",
    ")\n",
    "\n",
    "training_config = TrainingConfig(\n",
    "    lr=1e-4,\n",
    "    warmup_epochs=5,\n",
    "    max_epochs=50,\n",
    "    batch_size=32,\n",
    "    gradient_clip_val=1,\n",
    "    scheduler_patience=5,\n",
    "    scheduler_factor=0.5,\n",
    "    patience_min_delta=1e-6,\n",
    "    run_name=f\"n_mels={model_config.n_mels};groups={model_config.groups}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f5db6dd159c359",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "927bbda9af3177fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:15:40.530509Z",
     "start_time": "2025-03-23T17:15:39.657810Z"
    }
   },
   "outputs": [],
   "source": [
    "class SubsetSC(SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None, sample_rate: int = 16000):\n",
    "        super().__init__(\"./\", download=True)\n",
    "        self.binary_classes = ['yes', 'no']\n",
    "        self.target_length = sample_rate\n",
    "\n",
    "        def load_list(filename):\n",
    "            filepath = os.path.join(self._path, filename)\n",
    "            with open(filepath) as fileobj:\n",
    "                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n",
    "\n",
    "        if subset == \"validation\":\n",
    "            self._walker = load_list(\"validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = load_list(\"testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
    "            excludes = set(excludes)\n",
    "            self._walker = [w for w in self._walker if w not in excludes]\n",
    "\n",
    "        # Filter to keep only 'yes' and 'no' samples\n",
    "        self._walker = [w for w in self._walker if self.get_label_from_path(w) in self.binary_classes]\n",
    "\n",
    "    def get_label_from_path(self, path):\n",
    "        return os.path.normpath(path).split(os.path.sep)[-2]\n",
    "\n",
    "    def pad_or_truncate(self, waveform):\n",
    "        \"\"\"Pad or truncate waveform to target length.\"\"\"\n",
    "        current_length = waveform.shape[1]\n",
    "\n",
    "        if current_length > self.target_length:\n",
    "            # Truncate\n",
    "            return waveform[:, :self.target_length]\n",
    "        elif current_length < self.target_length:\n",
    "            # Pad with zeros\n",
    "            padding = torch.zeros(1, self.target_length - current_length)\n",
    "            return torch.cat([waveform, padding], dim=1)\n",
    "\n",
    "        return waveform\n",
    "\n",
    "    def __getitem__(self, n):\n",
    "        waveform, sample_rate, label, speaker_id, utterance_number = super().__getitem__(n)\n",
    "        waveform = self.pad_or_truncate(waveform)\n",
    "        # Convert labels to binary (0 for 'no', 1 for 'yes')\n",
    "        binary_label = torch.tensor(1 if label == 'yes' else 0, dtype=torch.long)\n",
    "        return waveform, sample_rate, binary_label, speaker_id, utterance_number\n",
    "\n",
    "train_set = SubsetSC(\"training\", sample_rate=model_config.sample_rate)\n",
    "val_set = SubsetSC(\"validation\", sample_rate=model_config.sample_rate)\n",
    "test_set = SubsetSC(\"testing\", sample_rate=model_config.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a0ae8cb159d7bfcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:15:40.547645Z",
     "start_time": "2025-03-23T17:15:40.545626Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=training_config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=training_config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=training_config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18934c71ad7e6d7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5bb12808e7a615d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:15:40.568756Z",
     "start_time": "2025-03-23T17:15:40.564269Z"
    }
   },
   "outputs": [],
   "source": [
    "class SpectroCNN(L.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_mels: int,\n",
    "            lr: float,\n",
    "            groups: int,\n",
    "            patience: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.patience =patience\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            LogMelFilterBanks(n_mels=n_mels),\n",
    "            nn.Conv1d(in_channels=n_mels, out_channels=16, kernel_size=3, padding=1, groups=groups),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16, 2),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        waveform, _, label, _, _ = batch\n",
    "        preds = self(waveform)\n",
    "        loss = self.loss(preds, label)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        waveform, _, label, _, _ = batch\n",
    "        preds = self(waveform)\n",
    "        loss = self.loss(preds, label)\n",
    "        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.lr\n",
    "        )\n",
    "\n",
    "        scheduler = {\n",
    "            'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',\n",
    "                factor=0.1,\n",
    "                patience=self.patience,\n",
    "                verbose=True,\n",
    "                min_lr=1e-6\n",
    "            ),\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "652d39cac2ff421f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:15:40.608031Z",
     "start_time": "2025-03-23T17:15:40.598228Z"
    }
   },
   "outputs": [],
   "source": [
    "class SpectroCNNTrainer:\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_config: ModelConfig,\n",
    "            training_config: TrainingConfig\n",
    "    ):\n",
    "        self.model_config = model_config\n",
    "        self.training_config = training_config\n",
    "        self.mlf_logger = None\n",
    "\n",
    "    def setup_trainer(self):\n",
    "        self.mlf_logger = MLFlowLogger(\n",
    "            experiment_name=self.training_config.mlflow_experiment_name,\n",
    "            tracking_uri=self.training_config.mlflow_tracking_uri,\n",
    "            run_name=self.training_config.run_name,\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=self.training_config.checkpoint_dir,\n",
    "            filename=\"best-model-{epoch:02d}-{val_loss:.2f}\",\n",
    "            save_top_k=1,\n",
    "            verbose=False,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "\n",
    "        early_stop_callback = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            min_delta=self.training_config.patience_min_delta,\n",
    "            patience=self.training_config.patience,\n",
    "            verbose=False,\n",
    "            mode='min'\n",
    "        )\n",
    "\n",
    "        lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "        trainer = L.Trainer(\n",
    "            max_epochs=self.training_config.max_epochs,\n",
    "            callbacks=[checkpoint_callback, lr_monitor, early_stop_callback],\n",
    "            logger=self.mlf_logger,\n",
    "            gradient_clip_val=self.training_config.gradient_clip_val,\n",
    "            accelerator=self.training_config.device,\n",
    "            devices=self.training_config.num_devices,\n",
    "        )\n",
    "\n",
    "        return trainer\n",
    "\n",
    "    def get_predictions(self, model, dataloader):\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                waveform, _, label, _, _ = batch\n",
    "                logits = model(waveform)\n",
    "                preds = torch.softmax(logits, dim=1)\n",
    "\n",
    "                all_preds.append(preds.cpu().numpy())\n",
    "                all_targets.append(label.cpu().numpy())\n",
    "\n",
    "        return np.concatenate(all_preds), np.concatenate(all_targets)\n",
    "\n",
    "    def on_fit_end(self, model, test_dataloader):\n",
    "        y_pred_proba, y_true = self.get_predictions(model, test_dataloader)\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "        metrics = {\n",
    "            \"test_accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"test_precision\": precision_score(y_true, y_pred, average='weighted'),\n",
    "            \"test_recall\": recall_score(y_true, y_pred, average='weighted'),\n",
    "            \"test_f1\": f1_score(y_true, y_pred, average='weighted')\n",
    "        }\n",
    "\n",
    "        class_report = classification_report(y_true, y_pred)\n",
    "\n",
    "        with open(\"classification_report.txt\", \"w\") as f:\n",
    "            f.write(class_report)\n",
    "        mlflow.log_artifact(\"classification_report.txt\")\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        mlflow.log_artifact('confusion_matrix.png')\n",
    "        plt.close()\n",
    "\n",
    "        if y_pred_proba.shape[1] == 2:\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            fpr, tpr, _ = roc_curve(y_true, y_pred_proba[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "            plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "                     label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Receiver Operating Characteristic')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.savefig('roc_curve.png')\n",
    "            mlflow.log_artifact('roc_curve.png')\n",
    "            plt.close()\n",
    "\n",
    "            metrics[\"roc_auc\"] = roc_auc\n",
    "\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        print(\"\\nValidation Metrics:\")\n",
    "        print(f\"Accuracy: {metrics['test_accuracy']:.4f}\")\n",
    "        print(f\"Precision: {metrics['test_precision']:.4f}\")\n",
    "        print(f\"Recall: {metrics['test_recall']:.4f}\")\n",
    "        print(f\"F1 Score: {metrics['test_f1']:.4f}\")\n",
    "        if y_pred_proba.shape[1] == 2:\n",
    "            print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    def calculate_macs(self, model, input_shape: tuple):\n",
    "        \"\"\"\n",
    "        Calculate MACs (Multiply-Accumulate Operations) for the model.\n",
    "        Args:\n",
    "            model: The PyTorch model\n",
    "            input_shape: Input tensor shape (batch_size, time)\n",
    "        Returns:\n",
    "            macs: Number of MACs\n",
    "            params: Number of parameters\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        input_shape = (1, 16000) \n",
    "        macs, params = get_model_complexity_info(\n",
    "            model, \n",
    "            input_shape,\n",
    "            as_strings=False,\n",
    "            print_per_layer_stat=True\n",
    "        )\n",
    "        return macs, params\n",
    "\n",
    "    def train(self, train_dataloader, val_dataloader, test_dataloader):\n",
    "        model = SpectroCNN(\n",
    "            n_mels=self.model_config.n_mels,\n",
    "            lr=self.training_config.lr,\n",
    "            groups=self.model_config.groups,\n",
    "            patience=self.training_config.patience,\n",
    "        )\n",
    "\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "        waveform, _, _, _, _ = next(iter(train_dataloader))\n",
    "        print(waveform.shape)\n",
    "        macs, _ = self.calculate_macs(model, waveform.shape)\n",
    "\n",
    "        print(f\"\\nModel Size Summary:\")\n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "        print(f\"MACs: {macs/1e6:.2f}M\")\n",
    "        print(f\"FLOPs: {(macs*2)/1e9:.2f}G\")\n",
    "\n",
    "        trainer = self.setup_trainer()\n",
    "\n",
    "        class TimingCallback(Callback):\n",
    "            def __init__(self):\n",
    "                self.epoch_start_time = None\n",
    "                self.training_start_time = None\n",
    "                self.epoch_times = []\n",
    "\n",
    "            def on_train_start(self, trainer, pl_module):\n",
    "                self.training_start_time = time.time()\n",
    "\n",
    "            def on_train_epoch_start(self, trainer, pl_module):\n",
    "                self.epoch_start_time = time.time()\n",
    "\n",
    "            def on_train_epoch_end(self, trainer, pl_module):\n",
    "                epoch_time = time.time() - self.epoch_start_time\n",
    "                self.epoch_times.append(epoch_time)\n",
    "\n",
    "                # Log epoch time to MLflow\n",
    "                mlflow.log_metric(\"epoch_time\", epoch_time, step=trainer.current_epoch)\n",
    "\n",
    "            def on_train_end(self, trainer, pl_module):\n",
    "                total_time = time.time() - self.training_start_time\n",
    "                avg_epoch_time = np.mean(self.epoch_times)\n",
    "\n",
    "                # Log summary timing metrics\n",
    "                mlflow.log_metrics({\n",
    "                    \"total_training_time\": total_time,\n",
    "                    \"average_epoch_time\": avg_epoch_time\n",
    "                })\n",
    "\n",
    "                # Create epoch timing plot\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(range(1, len(self.epoch_times) + 1), self.epoch_times, marker='o')\n",
    "                plt.title('Training Time per Epoch')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('Time (seconds)')\n",
    "                plt.grid(True)\n",
    "                plt.savefig('epoch_times.png')\n",
    "                mlflow.log_artifact('epoch_times.png')\n",
    "                plt.close()\n",
    "\n",
    "                # Log detailed timing data as CSV\n",
    "                epoch_timing_df = pd.DataFrame({\n",
    "                    'epoch': range(1, len(self.epoch_times) + 1),\n",
    "                    'time_seconds': self.epoch_times\n",
    "                })\n",
    "                epoch_timing_df.to_csv('epoch_times.csv', index=False)\n",
    "                mlflow.log_artifact('epoch_times.csv')\n",
    "\n",
    "        timing_callback = TimingCallback()\n",
    "        trainer.callbacks.append(timing_callback)\n",
    "\n",
    "        with mlflow.start_run(run_name=self.training_config.run_name) as run:\n",
    "            self.mlf_logger._run_id = run.info.run_id\n",
    "\n",
    "            model_params = {\"model_\" + k: v for k, v in asdict(self.model_config).items()}\n",
    "            training_params = {\"training_\" + k: v for k, v in asdict(self.training_config).items()}\n",
    "\n",
    "            model_stats = {\n",
    "                \"total_params\": total_params,\n",
    "                \"trainable_params\": trainable_params,\n",
    "                \"macs\": macs,\n",
    "                \"macs_M\": macs/1e6,\n",
    "                \"flops\": macs*2,\n",
    "                \"flops_G\": (macs*2)/1e9,\n",
    "            }\n",
    "\n",
    "            # Log all parameters\n",
    "            mlflow.log_params(model_params)\n",
    "            mlflow.log_params(training_params)\n",
    "            mlflow.log_params(model_stats)\n",
    "\n",
    "            trainer.fit(\n",
    "                model,\n",
    "                train_dataloaders=train_dataloader,\n",
    "                val_dataloaders=val_dataloader,\n",
    "            )\n",
    "\n",
    "            mlflow.pytorch.log_model(model, \"model\")\n",
    "            metrics = self.on_fit_end(model, test_dataloader)\n",
    "\n",
    "        return model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9b43a788e8a019fd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-23T17:15:40.615270Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (mps), used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type             | Params | Mode\n",
      "--------------------------------------------------\n",
      "0 | model | Sequential       | 322    | eval\n",
      "1 | loss  | CrossEntropyLoss | 0      | eval\n",
      "--------------------------------------------------\n",
      "322       Trainable params\n",
      "0         Non-trainable params\n",
      "322       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "11        Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 16000])\n",
      "SpectroCNN(\n",
      "  322, 100.000% Params, 33.15 KMac, 89.152% MACs, \n",
      "  (model): Sequential(\n",
      "    322, 100.000% Params, 33.15 KMac, 89.152% MACs, \n",
      "    (0): LogMelFilterBanks(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      "    (1): Conv1d(256, 79.503% Params, 25.86 KMac, 69.528% MACs, 80, 16, kernel_size=(3,), stride=(1,), padding=(1,), groups=16)\n",
      "    (2): ReLU(0, 0.000% Params, 1.62 KMac, 4.345% MACs, )\n",
      "    (3): BatchNorm1d(32, 9.938% Params, 3.23 KMac, 8.691% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): MaxPool1d(0, 0.000% Params, 1.62 KMac, 4.345% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): AdaptiveAvgPool1d(0, 0.000% Params, 800.0 Mac, 2.151% MACs, output_size=1)\n",
      "    (6): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "    (7): Linear(34, 10.559% Params, 34.0 Mac, 0.091% MACs, in_features=16, out_features=2, bias=True)\n",
      "    (8): Softmax(0, 0.000% Params, 0.0 Mac, 0.000% MACs, dim=None)\n",
      "  )\n",
      "  (loss): CrossEntropyLoss(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
      ")\n",
      "\n",
      "Model Size Summary:\n",
      "Total parameters: 322\n",
      "Trainable parameters: 322\n",
      "MACs: 0.04M\n",
      "FLOPs: 0.00G\n",
      "Epoch 49: 100%|█| 199/199 [00:06<00:00, 29.26it/s, v_num=a4c3, train_loss_step=0.444, val_loss_step=0.651, val_loss_epoch=0.432, train_loss_epoch"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|█| 199/199 [00:06<00:00, 29.20it/s, v_num=a4c3, train_loss_step=0.444, val_loss_step=0.651, val_loss_epoch=0.432, train_loss_epoch\n",
      "🏃 View run n_mels=80;groups=16 at: http://127.0.0.1:5000/#/experiments/0/runs/da75c971bfd74f89a02ed191786ca4c3\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/23 22:00:10 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "\u001b[31m2025/03/23 22:00:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Metrics:\n",
      "Accuracy: 0.8968\n",
      "Precision: 0.8976\n",
      "Recall: 0.8968\n",
      "F1 Score: 0.8968\n",
      "ROC AUC: 0.9558\n",
      "🏃 View run n_mels=80;groups=16 at: http://127.0.0.1:5000/#/experiments/0/runs/da75c971bfd74f89a02ed191786ca4c3\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "trainer = SpectroCNNTrainer(model_config, training_config)\n",
    "model, trainer = trainer.train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d8508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pixi Speech",
   "language": "python",
   "name": "pixi_speech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
